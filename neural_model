import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential # type: ignore
from tensorflow.keras.layers import Dense, Dropout # type: ignore
from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore
from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore
from sklearn.model_selection import train_test_split # type: ignore


reviews_data = pd.read_csv(r"C:\Users\prana\Documents\Sentiment-Analysis\synthetic_reviews_dataset_x4.csv")

Reviews = reviews_data['review'].values
labels = reviews_data['label'].values


tokenizer = Tokenizer(num_words = 5000)
tokenizer.fit_on_texts(Reviews)
sequences = tokenizer.texts_to_sequences(Reviews)

maxlen = 30
data = pad_sequences(sequences, maxlen = maxlen)
labels = np.array(labels)

X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)


model = Sequential([
    Dense(64, activation='relu', input_shape=(maxlen,)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])


model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

model.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=32)

loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy:.2f}")

#for test
new_reviews = [
    "This product exceeded my expectations",
    "Complete waste of money, avoid at all costs"
]

new_sequences = tokenizer.texts_to_sequences(new_reviews)

new_data = pad_sequences(new_sequences, maxlen = 30)

predictions = model.predict(new_data)

for i, pred in enumerate(predictions):
    sentiment = "Positive" if pred >= 0.5 else "Negative"

    print(f"Review: '{new_reviews[i]}'")
    print(f"Predicted Sentiment: {sentiment} (Score: {pred[0]:.2f})")
